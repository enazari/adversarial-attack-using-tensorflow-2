# Adversarial Attacks
In the repo there are a number of adversarial attack methods.
### Implemented Methods: 
* __Fast Gradient Sign Method(FGSM)__,  
* __One-step Target Class Method__,
* __Basic Iterative Fast Gradient Sign Method__,
* __Iterative Least-likely Class Method__.

These algorithms have been implemented with __Python__ via __Tensorflow-2__ in jupyter notebooks.

### Implementations based on following papers:
[__Explaining and Harnessing Adversarial Examples__](https://arxiv.org/abs/1412.6572)
[__Adversarial Machine Learning at Scale__](https://arxiv.org/abs/1611.01236)


#### Theses resources helped alot:
https://github.com/soumyac1999/FGSM-Keras, 
https://github.com/YunYang1994/TensorFlow2.0-Examples,
https://www.tensorflow.org/beta/tutorials/generative/adversarial_fgsm
