# Adversarial Attacks
In the repo there are a number of adversarial attack methods. These algorithms have been implemented with __Python__ via __Tensorflow-2__ in jupyter notebooks.

### Implemented Methods: 
* __Fast Gradient Sign Method(FGSM)__,  
* __One-step Target Class Method__,
* __Basic Iterative Fast Gradient Sign Method__,
* __Iterative Least-likely Class Method__.




##### Implementations are based on following papers:  
[__Explaining and Harnessing Adversarial Examples__](https://arxiv.org/abs/1412.6572)  
[__Adversarial Machine Learning at Scale__](https://arxiv.org/abs/1611.01236)




##### A lot of the credit goes to:  
https://github.com/soumyac1999/FGSM-Keras,  
https://github.com/YunYang1994/TensorFlow2.0-Examples,  
https://www.tensorflow.org/beta/tutorials/generative/adversarial_fgsm
